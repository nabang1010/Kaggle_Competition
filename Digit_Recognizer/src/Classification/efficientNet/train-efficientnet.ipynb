{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision import models\nimport matplotlib.pyplot as plt\n\n\nimport numpy as np\nimport wandb\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm\nimport argparse\nfrom PIL import Image\n\nfrom sklearn.metrics import f1_score, precision_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-24T02:58:34.560768Z","iopub.execute_input":"2022-11-24T02:58:34.561835Z","iopub.status.idle":"2022-11-24T02:58:34.578612Z","shell.execute_reply.started":"2022-11-24T02:58:34.561783Z","shell.execute_reply":"2022-11-24T02:58:34.577528Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-11-24T02:58:34.586255Z","iopub.execute_input":"2022-11-24T02:58:34.588123Z","iopub.status.idle":"2022-11-24T02:58:34.597449Z","shell.execute_reply.started":"2022-11-24T02:58:34.588094Z","shell.execute_reply":"2022-11-24T02:58:34.596393Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"class Model_EfficientNet(nn.Module):\n    def __init__(self, model_type):\n        super(Model_EfficientNet, self).__init__()\n\n        if model_type == \"EfficientNet_v2_s\":\n            self.model = models.efficientnet.efficientnet_v2_s(pretrained=True)\n        elif model_type == \"EfficientNet_v2_m\":\n            self.model = models.efficientnet.efficientnet_v2_m(pretrained=True)\n        elif model_type == \"EfficientNet_v2_l\":\n            self.model = models.efficientnet.efficientnet_v2_l(pretrained=True)\n        elif model_type == \"EfficientNet_B0\":\n            self.model = models.efficientnet.efficientnet_b0(pretrained=True)\n        elif model_type == \"EfficientNet_B1\":\n            self.model = models.efficientnet.efficientnet_b1(pretrained=True)\n        elif model_type == \"EfficientNet_B2\":\n            self.model = models.efficientnet.efficientnet_b2(pretrained=True)\n        elif model_type == \"EfficientNet_B3\":\n            self.model = models.efficientnet.efficientnet_b3(pretrained=True)\n        elif model_type == \"EfficientNet_B4\":\n            self.model = models.efficientnet.efficientnet_b4(pretrained=True)\n        elif model_type == \"EfficientNet_B5\":\n            self.model = models.efficientnet.efficientnet_b5(pretrained=True)\n        elif model_type == \"EfficientNet_B6\":\n            self.model = models.efficientnet.efficientnet_b6(pretrained=True)\n        elif model_type == \"EfficientNet_B7\":\n            self.model = models.efficientnet.efficientnet_b7(pretrained=True)\n        self.model.classifier[1] = nn.Linear(2560, 10, bias=True)\n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-11-24T02:58:34.599336Z","iopub.execute_input":"2022-11-24T02:58:34.600489Z","iopub.status.idle":"2022-11-24T02:58:34.616887Z","shell.execute_reply.started":"2022-11-24T02:58:34.600449Z","shell.execute_reply":"2022-11-24T02:58:34.615788Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class Digit_Dataset(Dataset):\n    def __init__(self, df_data, transforms=None):\n        self.data = df_data\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img = self.data.iloc[idx, 1:].values.reshape(28, 28).astype(np.uint8)\n        # 3 channels\n        img = np.stack((img,) * 3, axis=-1)\n        label = self.data.iloc[idx, 0]\n        if self.transforms:\n            img = self.transforms(img)\n        return img, label\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T02:58:34.621552Z","iopub.execute_input":"2022-11-24T02:58:34.624795Z","iopub.status.idle":"2022-11-24T02:58:34.634272Z","shell.execute_reply.started":"2022-11-24T02:58:34.624765Z","shell.execute_reply":"2022-11-24T02:58:34.633066Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class Training_Model:\n    def __init__(self, model_type, model, optimizer, criterion, dict_dataloader):\n        self.model_type = model_type\n        self.model = model.to(device)\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.train_loader = dict_dataloader[\"train_loader\"]\n        self.val_loader = dict_dataloader[\"val_loader\"]\n        self.best_f1_score = 0\n\n    def train(self, epochs):\n        print(\"============TRAINING START {}============\".format(epochs))\n        self.model.train()\n        total_loss = 0\n        preds, targets = [], []\n        for batch_idx, (data, target) in enumerate(tqdm(self.train_loader)):\n            data = data.to(device)\n            target = target.to(device)\n            self.optimizer.zero_grad()\n            output = self.model(data)\n            loss = self.criterion(output, target)\n            loss.backward()\n            self.optimizer.step()\n            total_loss += loss.item()\n            _, predicted = torch.max(output.data, 1)\n            preds += predicted.tolist()\n            targets += target.tolist()\n\n        total_loss = round(total_loss / len(self.train_loader), 4)\n        precision_scr = round(\n            precision_score(targets, preds, average=\"macro\"),\n            4,\n        )\n        accuracy_scr = round(\n            accuracy_score(targets, preds),\n            4,\n        )\n        train_f1_scr = round(\n            f1_score(targets, preds, average=\"macro\"),\n            4,\n        )\n        print(\n            \"train_loss: {}, train_precision: {}, train_accuracy: {}, train_f1_score: {}\".format(\n                total_loss, precision_scr, accuracy_scr, train_f1_scr\n            )\n        )\n        wandb.log(\n            {\n                \"train_loss\": total_loss,\n                \"train_precision_score\": precision_scr,\n                \"train_accuracy_score\": accuracy_scr,\n                \"train_f1_score\": train_f1_scr,\n            }\n        )\n\n    def validation(self, epochs):\n        print(\"============VAL START {}============\".format(epochs))\n        self.model.eval()\n        total_loss = 0\n        preds, targets = [], []\n        for batch_idx, (data, target) in enumerate(tqdm(self.val_loader)):\n            data = data.to(device)\n            target = target.to(device)\n\n            with torch.no_grad():\n                output = self.model(data)\n                loss = self.criterion(output, target)\n                total_loss += loss.item()\n                _, predicted = torch.max(output.data, 1)\n\n                preds += predicted.tolist()\n                targets += target.tolist()\n        total_loss = round(total_loss / len(self.val_loader), 4)\n        precision_scr = round(precision_score(targets, preds, average=\"macro\"), 4)\n        accuracy_scr = round(accuracy_score(targets, preds), 4)\n        val_f1_scr = round(f1_score(targets, preds, average=\"macro\"), 4)\n        print(\n            \"val_loss: {}, val_precision: {}, val_accuracy: {}, val_f1_score: {}\".format(\n                total_loss, precision_scr, accuracy_scr, val_f1_scr\n            )\n        )\n        wandb.log(\n            {\n                \"val_loss\": total_loss,\n                \"val_precision_score\": precision_scr,\n                \"val_accuracy_score\": accuracy_scr,\n                \"val_f1_score\": val_f1_scr,\n            }\n        )\n        if val_f1_scr > self.best_f1_score and val_f1_scr > 0.99   :\n            self.best_f1_score = val_f1_scr\n            torch.save(\n                self.model.state_dict(),\n                \"/kaggle/working/{}_f1_{}.pt\".format(self.model_type, val_f1_scr),\n            )\n#             torch.jit.save(\n#                 torch.jit.script(self.model),\n#                 self.model.state_dict(),\n#                 \"/kaggle/working/{}_jit_f1_{}.pt\".format(\"vgg_16\", val_f1_scr),\n#             )","metadata":{"execution":{"iopub.status.busy":"2022-11-24T02:58:34.636806Z","iopub.execute_input":"2022-11-24T02:58:34.637443Z","iopub.status.idle":"2022-11-24T02:58:34.662009Z","shell.execute_reply.started":"2022-11-24T02:58:34.637193Z","shell.execute_reply":"2022-11-24T02:58:34.660687Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def get_loader(csv_file, transforms, batch_size=64):\n    dataset = Digit_Dataset(csv_file, transforms)\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    return loader\n\n\ndef get_input():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model_type\", type=str, default=\"EfficientNet_v2_s\")\n    parser.add_argument(\"--batch_size\", type=int, default=8)\n    parser.add_argument(\"--epochs\", type=int, default=20)\n    parser.add_argument(\"--lr\", type=float, default=0.001)\n    parser.add_argument(\"--seed\", type=int, default=10)\n    parser.add_argument(\"--weight_decay\", type=float, default=0.0001)\n    args = parser.parse_args()\n    return args\n\n\ndef config_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T02:58:34.663562Z","iopub.execute_input":"2022-11-24T02:58:34.664218Z","iopub.status.idle":"2022-11-24T02:58:34.682803Z","shell.execute_reply.started":"2022-11-24T02:58:34.664182Z","shell.execute_reply":"2022-11-24T02:58:34.681591Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"config_seed(10)\n\nbatch_size = 128\nepochs = 50\nlr = 0.001\nweight_decay = 0.0001\n\ndata = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n\ntrain_data, val_data = train_test_split(data, test_size=0.2, random_state=10)\n\ntransforms = transforms.Compose(\n    [\n        transforms.ToPILImage(),\n        transforms.Resize((33, 33)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5,), std=(0.5,)),\n    ]\n)\n\ntrain_loader = get_loader(train_data, transforms=transforms, batch_size=batch_size)\nval_loader = get_loader(val_data, transforms=transforms, batch_size=batch_size)\n\ndict_dataloader = {\"train_loader\": train_loader, \"val_loader\": val_loader}\nmodel_type = \"EfficientNet_B7\"\nmodel = Model_EfficientNet(model_type)\noptimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\ncriterion = nn.CrossEntropyLoss()\n\nwandb.init(\n    project=\"Digit_Recognizer\",\n    group=\"EfficientNet\",\n    name=\"{}_{}_{}_{}\".format(model_type, batch_size, epochs, lr),\n)\n\nwandb.watch(model)\n\ntraining_model = Training_Model(\n    model_type=model_type,\n    model=model,\n    optimizer=optimizer,\n    criterion=criterion,\n    dict_dataloader=dict_dataloader\n)\n\nfor epoch in range(epochs):\n    training_model.train(epoch)\n    training_model.validation(epoch)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T02:58:34.684518Z","iopub.execute_input":"2022-11-24T02:58:34.685193Z","iopub.status.idle":"2022-11-24T04:47:44.903362Z","shell.execute_reply.started":"2022-11-24T02:58:34.685156Z","shell.execute_reply":"2022-11-24T04:47:44.902336Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b7_lukemelas-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b7_lukemelas-dcc49843.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/255M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24bf379db15f46a387626592f24daf3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:2qnwfs9j) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">EfficientNet_B0_128_50_0.001</strong>: <a href=\"https://wandb.ai/lban_nlp_vinbigdata/Digit_Recognizer/runs/2qnwfs9j\" target=\"_blank\">https://wandb.ai/lban_nlp_vinbigdata/Digit_Recognizer/runs/2qnwfs9j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20221124_025630-2qnwfs9j/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:2qnwfs9j). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20221124_025902-14861myn</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/lban_nlp_vinbigdata/Digit_Recognizer/runs/14861myn\" target=\"_blank\">EfficientNet_B7_128_50_0.001</a></strong> to <a href=\"https://wandb.ai/lban_nlp_vinbigdata/Digit_Recognizer\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stdout","text":"============TRAINING START 0============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [02:07<00:00,  2.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.175, train_precision: 0.9527, train_accuracy: 0.953, train_f1_score: 0.9526\n============VAL START 0============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0766, val_precision: 0.9798, val_accuracy: 0.9793, val_f1_score: 0.9793\n============TRAINING START 1============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0539, train_precision: 0.9866, train_accuracy: 0.9866, train_f1_score: 0.9866\n============VAL START 1============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.163, val_precision: 0.984, val_accuracy: 0.983, val_f1_score: 0.9831\n============TRAINING START 2============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:56<00:00,  2.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0413, train_precision: 0.9902, train_accuracy: 0.9902, train_f1_score: 0.9901\n============VAL START 2============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.2794, val_precision: 0.9714, val_accuracy: 0.9695, val_f1_score: 0.9687\n============TRAINING START 3============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0419, train_precision: 0.9896, train_accuracy: 0.9896, train_f1_score: 0.9896\n============VAL START 3============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.1201, val_precision: 0.9805, val_accuracy: 0.98, val_f1_score: 0.9799\n============TRAINING START 4============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0335, train_precision: 0.9913, train_accuracy: 0.9913, train_f1_score: 0.9913\n============VAL START 4============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.1704, val_precision: 0.9773, val_accuracy: 0.9752, val_f1_score: 0.975\n============TRAINING START 5============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:56<00:00,  2.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0343, train_precision: 0.9904, train_accuracy: 0.9905, train_f1_score: 0.9904\n============VAL START 5============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.1533, val_precision: 0.9776, val_accuracy: 0.9773, val_f1_score: 0.9769\n============TRAINING START 6============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:56<00:00,  2.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0294, train_precision: 0.993, train_accuracy: 0.993, train_f1_score: 0.993\n============VAL START 6============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.27, val_precision: 0.9626, val_accuracy: 0.95, val_f1_score: 0.9522\n============TRAINING START 7============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0291, train_precision: 0.9924, train_accuracy: 0.9924, train_f1_score: 0.9924\n============VAL START 7============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.16, val_precision: 0.9797, val_accuracy: 0.9785, val_f1_score: 0.9784\n============TRAINING START 8============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:56<00:00,  2.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0237, train_precision: 0.9941, train_accuracy: 0.9941, train_f1_score: 0.9941\n============VAL START 8============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.1226, val_precision: 0.9835, val_accuracy: 0.9829, val_f1_score: 0.9828\n============TRAINING START 9============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:56<00:00,  2.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0222, train_precision: 0.9944, train_accuracy: 0.9944, train_f1_score: 0.9944\n============VAL START 9============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0961, val_precision: 0.9852, val_accuracy: 0.9852, val_f1_score: 0.9852\n============TRAINING START 10============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:56<00:00,  2.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0272, train_precision: 0.993, train_accuracy: 0.9931, train_f1_score: 0.9931\n============VAL START 10============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.1165, val_precision: 0.9863, val_accuracy: 0.9857, val_f1_score: 0.9859\n============TRAINING START 11============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0213, train_precision: 0.9946, train_accuracy: 0.9946, train_f1_score: 0.9946\n============VAL START 11============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.1303, val_precision: 0.9838, val_accuracy: 0.983, val_f1_score: 0.9831\n============TRAINING START 12============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:56<00:00,  2.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0176, train_precision: 0.9954, train_accuracy: 0.9954, train_f1_score: 0.9954\n============VAL START 12============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.1126, val_precision: 0.9842, val_accuracy: 0.9826, val_f1_score: 0.983\n============TRAINING START 13============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0204, train_precision: 0.9946, train_accuracy: 0.9947, train_f1_score: 0.9946\n============VAL START 13============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.1053, val_precision: 0.9766, val_accuracy: 0.971, val_f1_score: 0.9726\n============TRAINING START 14============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0196, train_precision: 0.9945, train_accuracy: 0.9946, train_f1_score: 0.9945\n============VAL START 14============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.1539, val_precision: 0.9787, val_accuracy: 0.9774, val_f1_score: 0.9778\n============TRAINING START 15============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0183, train_precision: 0.9952, train_accuracy: 0.9952, train_f1_score: 0.9952\n============VAL START 15============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0608, val_precision: 0.9897, val_accuracy: 0.9895, val_f1_score: 0.9895\n============TRAINING START 16============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0192, train_precision: 0.995, train_accuracy: 0.9951, train_f1_score: 0.9951\n============VAL START 16============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0685, val_precision: 0.9881, val_accuracy: 0.9881, val_f1_score: 0.9879\n============TRAINING START 17============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0176, train_precision: 0.9953, train_accuracy: 0.9954, train_f1_score: 0.9953\n============VAL START 17============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0588, val_precision: 0.9852, val_accuracy: 0.9849, val_f1_score: 0.9849\n============TRAINING START 18============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0163, train_precision: 0.9956, train_accuracy: 0.9956, train_f1_score: 0.9956\n============VAL START 18============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.046, val_precision: 0.9896, val_accuracy: 0.9895, val_f1_score: 0.9895\n============TRAINING START 19============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0187, train_precision: 0.9948, train_accuracy: 0.9948, train_f1_score: 0.9947\n============VAL START 19============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0869, val_precision: 0.9816, val_accuracy: 0.9807, val_f1_score: 0.9807\n============TRAINING START 20============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.017, train_precision: 0.9954, train_accuracy: 0.9954, train_f1_score: 0.9954\n============VAL START 20============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0422, val_precision: 0.9879, val_accuracy: 0.9879, val_f1_score: 0.9879\n============TRAINING START 21============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0145, train_precision: 0.9961, train_accuracy: 0.9961, train_f1_score: 0.9961\n============VAL START 21============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0525, val_precision: 0.9869, val_accuracy: 0.9864, val_f1_score: 0.9862\n============TRAINING START 22============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0136, train_precision: 0.9963, train_accuracy: 0.9963, train_f1_score: 0.9963\n============VAL START 22============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0441, val_precision: 0.9892, val_accuracy: 0.9889, val_f1_score: 0.9889\n============TRAINING START 23============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0145, train_precision: 0.9962, train_accuracy: 0.9963, train_f1_score: 0.9962\n============VAL START 23============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0415, val_precision: 0.9891, val_accuracy: 0.9892, val_f1_score: 0.9891\n============TRAINING START 24============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0172, train_precision: 0.9953, train_accuracy: 0.9953, train_f1_score: 0.9953\n============VAL START 24============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0559, val_precision: 0.9853, val_accuracy: 0.9856, val_f1_score: 0.9853\n============TRAINING START 25============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0127, train_precision: 0.9969, train_accuracy: 0.9969, train_f1_score: 0.9969\n============VAL START 25============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0577, val_precision: 0.9867, val_accuracy: 0.9864, val_f1_score: 0.9865\n============TRAINING START 26============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:59<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0117, train_precision: 0.9967, train_accuracy: 0.9967, train_f1_score: 0.9967\n============VAL START 26============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.045, val_precision: 0.9898, val_accuracy: 0.9898, val_f1_score: 0.9896\n============TRAINING START 27============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0134, train_precision: 0.9962, train_accuracy: 0.9962, train_f1_score: 0.9962\n============VAL START 27============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0341, val_precision: 0.9908, val_accuracy: 0.9908, val_f1_score: 0.9908\n============TRAINING START 28============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0135, train_precision: 0.9964, train_accuracy: 0.9964, train_f1_score: 0.9964\n============VAL START 28============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0435, val_precision: 0.9885, val_accuracy: 0.9883, val_f1_score: 0.9883\n============TRAINING START 29============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0154, train_precision: 0.9954, train_accuracy: 0.9954, train_f1_score: 0.9954\n============VAL START 29============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0294, val_precision: 0.9923, val_accuracy: 0.9924, val_f1_score: 0.9923\n============TRAINING START 30============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0146, train_precision: 0.9962, train_accuracy: 0.9962, train_f1_score: 0.9962\n============VAL START 30============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0429, val_precision: 0.988, val_accuracy: 0.9881, val_f1_score: 0.9878\n============TRAINING START 31============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0083, train_precision: 0.9974, train_accuracy: 0.9974, train_f1_score: 0.9974\n============VAL START 31============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0384, val_precision: 0.9892, val_accuracy: 0.9892, val_f1_score: 0.9891\n============TRAINING START 32============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0107, train_precision: 0.9967, train_accuracy: 0.9967, train_f1_score: 0.9967\n============VAL START 32============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0317, val_precision: 0.9916, val_accuracy: 0.9915, val_f1_score: 0.9915\n============TRAINING START 33============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0114, train_precision: 0.9966, train_accuracy: 0.9966, train_f1_score: 0.9966\n============VAL START 33============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0379, val_precision: 0.9893, val_accuracy: 0.9892, val_f1_score: 0.9891\n============TRAINING START 34============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0158, train_precision: 0.9959, train_accuracy: 0.9959, train_f1_score: 0.9959\n============VAL START 34============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0309, val_precision: 0.9914, val_accuracy: 0.9914, val_f1_score: 0.9913\n============TRAINING START 35============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0108, train_precision: 0.9973, train_accuracy: 0.9973, train_f1_score: 0.9973\n============VAL START 35============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0304, val_precision: 0.9916, val_accuracy: 0.9917, val_f1_score: 0.9916\n============TRAINING START 36============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0096, train_precision: 0.9969, train_accuracy: 0.9969, train_f1_score: 0.9969\n============VAL START 36============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0301, val_precision: 0.9916, val_accuracy: 0.9917, val_f1_score: 0.9916\n============TRAINING START 37============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0098, train_precision: 0.9975, train_accuracy: 0.9975, train_f1_score: 0.9975\n============VAL START 37============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0312, val_precision: 0.9909, val_accuracy: 0.9908, val_f1_score: 0.9908\n============TRAINING START 38============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0103, train_precision: 0.9971, train_accuracy: 0.9971, train_f1_score: 0.9971\n============VAL START 38============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0333, val_precision: 0.9899, val_accuracy: 0.9899, val_f1_score: 0.9897\n============TRAINING START 39============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0096, train_precision: 0.9974, train_accuracy: 0.9974, train_f1_score: 0.9974\n============VAL START 39============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0431, val_precision: 0.9874, val_accuracy: 0.9871, val_f1_score: 0.9871\n============TRAINING START 40============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.013, train_precision: 0.9964, train_accuracy: 0.9965, train_f1_score: 0.9964\n============VAL START 40============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0351, val_precision: 0.9899, val_accuracy: 0.99, val_f1_score: 0.9899\n============TRAINING START 41============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0075, train_precision: 0.998, train_accuracy: 0.9979, train_f1_score: 0.998\n============VAL START 41============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0386, val_precision: 0.9906, val_accuracy: 0.9904, val_f1_score: 0.9904\n============TRAINING START 42============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0135, train_precision: 0.9966, train_accuracy: 0.9966, train_f1_score: 0.9966\n============VAL START 42============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0401, val_precision: 0.9896, val_accuracy: 0.9895, val_f1_score: 0.9895\n============TRAINING START 43============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0085, train_precision: 0.9979, train_accuracy: 0.9979, train_f1_score: 0.9979\n============VAL START 43============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0325, val_precision: 0.9916, val_accuracy: 0.9917, val_f1_score: 0.9917\n============TRAINING START 44============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0083, train_precision: 0.9977, train_accuracy: 0.9977, train_f1_score: 0.9977\n============VAL START 44============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0639, val_precision: 0.985, val_accuracy: 0.9845, val_f1_score: 0.9846\n============TRAINING START 45============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0114, train_precision: 0.9967, train_accuracy: 0.9967, train_f1_score: 0.9967\n============VAL START 45============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0341, val_precision: 0.991, val_accuracy: 0.991, val_f1_score: 0.9909\n============TRAINING START 46============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0091, train_precision: 0.9973, train_accuracy: 0.9973, train_f1_score: 0.9973\n============VAL START 46============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.029, val_precision: 0.9922, val_accuracy: 0.9923, val_f1_score: 0.9922\n============TRAINING START 47============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.011, train_precision: 0.9965, train_accuracy: 0.9965, train_f1_score: 0.9965\n============VAL START 47============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0899, val_precision: 0.9775, val_accuracy: 0.9752, val_f1_score: 0.9755\n============TRAINING START 48============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:57<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.0126, train_precision: 0.9964, train_accuracy: 0.9964, train_f1_score: 0.9964\n============VAL START 48============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:11<00:00,  5.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0304, val_precision: 0.9915, val_accuracy: 0.9914, val_f1_score: 0.9914\n============TRAINING START 49============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:58<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_loss: 0.007, train_precision: 0.9983, train_accuracy: 0.9983, train_f1_score: 0.9983\n============VAL START 49============\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 66/66 [00:12<00:00,  5.46it/s]","output_type":"stream"},{"name":"stdout","text":"val_loss: 0.0337, val_precision: 0.9904, val_accuracy: 0.9904, val_f1_score: 0.9903\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model_type = \"EfficientNet_B7\"\nmodel = Model_EfficientNet(model_type)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:49:26.944565Z","iopub.execute_input":"2022-11-24T04:49:26.945031Z","iopub.status.idle":"2022-11-24T04:49:28.702809Z","shell.execute_reply.started":"2022-11-24T04:49:26.944986Z","shell.execute_reply":"2022-11-24T04:49:28.701852Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/working/EfficientNet_B7_f1_0.9923.pt\"))","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:49:39.072659Z","iopub.execute_input":"2022-11-24T04:49:39.073378Z","iopub.status.idle":"2022-11-24T04:49:39.707387Z","shell.execute_reply.started":"2022-11-24T04:49:39.073340Z","shell.execute_reply":"2022-11-24T04:49:39.706285Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"model.eval()","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:49:43.393594Z","iopub.execute_input":"2022-11-24T04:49:43.393983Z","iopub.status.idle":"2022-11-24T04:49:43.427178Z","shell.execute_reply.started":"2022-11-24T04:49:43.393950Z","shell.execute_reply":"2022-11-24T04:49:43.426123Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"Model_EfficientNet(\n  (model): EfficientNet(\n    (features): Sequential(\n      (0): ConvNormActivation(\n        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (2): SiLU(inplace=True)\n      )\n      (1): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (2): ConvNormActivation(\n              (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (2): ConvNormActivation(\n              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.0036363636363636364, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (2): ConvNormActivation(\n              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.007272727272727273, mode=row)\n        )\n        (3): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (2): ConvNormActivation(\n              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.01090909090909091, mode=row)\n        )\n      )\n      (2): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n              (1): BatchNorm2d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.014545454545454545, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.01818181818181818, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.02181818181818182, mode=row)\n        )\n        (3): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.025454545454545455, mode=row)\n        )\n        (4): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.02909090909090909, mode=row)\n        )\n        (5): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.03272727272727273, mode=row)\n        )\n        (6): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.03636363636363636, mode=row)\n        )\n      )\n      (3): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n              (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(288, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.04363636363636364, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.04727272727272727, mode=row)\n        )\n        (3): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.05090909090909091, mode=row)\n        )\n        (4): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.05454545454545454, mode=row)\n        )\n        (5): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.05818181818181818, mode=row)\n        )\n        (6): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.06181818181818183, mode=row)\n        )\n      )\n      (4): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=480, bias=False)\n              (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.06545454545454546, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.06909090909090909, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.07272727272727272, mode=row)\n        )\n        (3): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.07636363636363637, mode=row)\n        )\n        (4): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n        )\n        (5): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.08363636363636365, mode=row)\n        )\n        (6): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.08727272727272728, mode=row)\n        )\n        (7): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n        )\n        (8): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.09454545454545454, mode=row)\n        )\n        (9): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.09818181818181819, mode=row)\n        )\n      )\n      (5): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n              (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(960, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.10181818181818182, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.10545454545454547, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.10909090909090909, mode=row)\n        )\n        (3): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.11272727272727273, mode=row)\n        )\n        (4): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.11636363636363636, mode=row)\n        )\n        (5): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.12000000000000001, mode=row)\n        )\n        (6): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.12363636363636366, mode=row)\n        )\n        (7): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.12727272727272726, mode=row)\n        )\n        (8): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.13090909090909092, mode=row)\n        )\n        (9): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1344, bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(224, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.13454545454545455, mode=row)\n        )\n      )\n      (6): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(1344, 1344, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=1344, bias=False)\n              (1): BatchNorm2d(1344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(1344, 56, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(56, 1344, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.13818181818181818, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.14181818181818184, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.14545454545454545, mode=row)\n        )\n        (3): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1490909090909091, mode=row)\n        )\n        (4): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.15272727272727274, mode=row)\n        )\n        (5): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.15636363636363634, mode=row)\n        )\n        (6): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n        )\n        (7): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.16363636363636364, mode=row)\n        )\n        (8): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1672727272727273, mode=row)\n        )\n        (9): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.17090909090909093, mode=row)\n        )\n        (10): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.17454545454545456, mode=row)\n        )\n        (11): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1781818181818182, mode=row)\n        )\n        (12): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.18181818181818182, mode=row)\n        )\n      )\n      (7): Sequential(\n        (0): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n              (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(640, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.18545454545454548, mode=row)\n        )\n        (1): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n              (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(640, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.1890909090909091, mode=row)\n        )\n        (2): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n              (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(640, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.19272727272727275, mode=row)\n        )\n        (3): MBConv(\n          (block): Sequential(\n            (0): ConvNormActivation(\n              (0): Conv2d(640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (1): ConvNormActivation(\n              (0): Conv2d(3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)\n              (1): BatchNorm2d(3840, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n              (2): SiLU(inplace=True)\n            )\n            (2): SqueezeExcitation(\n              (avgpool): AdaptiveAvgPool2d(output_size=1)\n              (fc1): Conv2d(3840, 160, kernel_size=(1, 1), stride=(1, 1))\n              (fc2): Conv2d(160, 3840, kernel_size=(1, 1), stride=(1, 1))\n              (activation): SiLU(inplace=True)\n              (scale_activation): Sigmoid()\n            )\n            (3): ConvNormActivation(\n              (0): Conv2d(3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(640, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            )\n          )\n          (stochastic_depth): StochasticDepth(p=0.19636363636363638, mode=row)\n        )\n      )\n      (8): ConvNormActivation(\n        (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(2560, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (2): SiLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=1)\n    (classifier): Sequential(\n      (0): Dropout(p=0.5, inplace=True)\n      (1): Linear(in_features=2560, out_features=10, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T04:49:57.931672Z","iopub.execute_input":"2022-11-24T04:49:57.932290Z","iopub.status.idle":"2022-11-24T04:49:58.127472Z","shell.execute_reply.started":"2022-11-24T04:49:57.932236Z","shell.execute_reply":"2022-11-24T04:49:58.113780Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"DF_test = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nDF_test","metadata":{"execution":{"iopub.status.busy":"2022-11-24T05:28:01.542581Z","iopub.execute_input":"2022-11-24T05:28:01.542972Z","iopub.status.idle":"2022-11-24T05:28:02.824531Z","shell.execute_reply.started":"2022-11-24T05:28:01.542938Z","shell.execute_reply":"2022-11-24T05:28:02.822468Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0           0       0       0       0       0       0       0       0       0   \n1           0       0       0       0       0       0       0       0       0   \n2           0       0       0       0       0       0       0       0       0   \n3           0       0       0       0       0       0       0       0       0   \n4           0       0       0       0       0       0       0       0       0   \n...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n27995       0       0       0       0       0       0       0       0       0   \n27996       0       0       0       0       0       0       0       0       0   \n27997       0       0       0       0       0       0       0       0       0   \n27998       0       0       0       0       0       0       0       0       0   \n27999       0       0       0       0       0       0       0       0       0   \n\n       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n0           0  ...         0         0         0         0         0   \n1           0  ...         0         0         0         0         0   \n2           0  ...         0         0         0         0         0   \n3           0  ...         0         0         0         0         0   \n4           0  ...         0         0         0         0         0   \n...       ...  ...       ...       ...       ...       ...       ...   \n27995       0  ...         0         0         0         0         0   \n27996       0  ...         0         0         0         0         0   \n27997       0  ...         0         0         0         0         0   \n27998       0  ...         0         0         0         0         0   \n27999       0  ...         0         0         0         0         0   \n\n       pixel779  pixel780  pixel781  pixel782  pixel783  \n0             0         0         0         0         0  \n1             0         0         0         0         0  \n2             0         0         0         0         0  \n3             0         0         0         0         0  \n4             0         0         0         0         0  \n...         ...       ...       ...       ...       ...  \n27995         0         0         0         0         0  \n27996         0         0         0         0         0  \n27997         0         0         0         0         0  \n27998         0         0         0         0         0  \n27999         0         0         0         0         0  \n\n[28000 rows x 784 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27995</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27996</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27997</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27998</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27999</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>28000 rows × 784 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from torchvision import transforms\nDF_submission = pd.DataFrame(columns=[\"ImageId\", \"Label\"])\ntransforms = transforms.Compose(\n    [\n        transforms.ToPILImage(),\n        transforms.Resize((33, 33)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5,), std=(0.5,)),\n    ]\n)\nfor row in tqdm(range(DF_test.shape[0])):\n    img = DF_test.iloc[row, :].values\n    img = img.reshape(28, 28).astype(np.uint8)\n#     plt.imshow(img)\n#     plt.show()\n    # 3 channel\n    img = np.stack((img,) * 3, axis=-1)\n    img = transforms(img)\n    \n    img = img.to(device)\n    img = img.unsqueeze(0)\n    with torch.no_grad():\n        output = model(img)\n        _, predicted = torch.max(output.data, 1)\n        DF_test.iloc[row, :] = predicted.item()\n#         print(predicted.item())\n        DF_submission = DF_submission.append( {\"ImageId\": row+1, \"Label\": predicted.item()}, ignore_index=True)\nDF_submission.to_csv(\"/kaggle/working/EfficientNet_B7_f1_0.9923_submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T05:29:20.778253Z","iopub.execute_input":"2022-11-24T05:29:20.778691Z","iopub.status.idle":"2022-11-24T05:43:38.556132Z","shell.execute_reply.started":"2022-11-24T05:29:20.778652Z","shell.execute_reply":"2022-11-24T05:43:38.555206Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"100%|██████████| 28000/28000 [14:17<00:00, 32.64it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# !rm -rf /kaggle/working/EfficientNet_B7_f1_0.9923_submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-11-24T05:29:03.202349Z","iopub.execute_input":"2022-11-24T05:29:03.202703Z","iopub.status.idle":"2022-11-24T05:29:04.231374Z","shell.execute_reply.started":"2022-11-24T05:29:03.202671Z","shell.execute_reply":"2022-11-24T05:29:04.229911Z"},"trusted":true},"execution_count":42,"outputs":[]}]}